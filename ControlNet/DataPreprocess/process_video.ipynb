{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # 代入OpenCV模块\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from getBBox import get_BBox\n",
    "from face_alignment.detection.sfd.sfd_detector import SFDDetector\n",
    "\n",
    "# get face detector\n",
    "face_detector = SFDDetector(device='cuda')\n",
    "\n",
    "# 全局变量\n",
    "video_path = '/home/wenchi/zxy/HSD/jjk_video_2.mp4'  # 视频地址\n",
    "extract_root_path = '/data1/wc_log/zxy/custom_dataset'  # 存放帧图片的位置\n",
    "extract_frequency = 6  # 帧提取频率\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path):\n",
    "    # 实例化视频对象\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    frame_list = []\n",
    "\n",
    "    # 循环遍历视频中的所有帧\n",
    "    while True:\n",
    "        # 逐帧读取\n",
    "        _, frame = video.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "        # 按照设置的频率保存图片\n",
    "        if frame_count % extract_frequency == 0:\n",
    "            frame_list.append(frame)\n",
    "        frame_count += 1  # 读取视频帧数＋1\n",
    "\n",
    "    return frame_list\n",
    "\n",
    "\n",
    "def crop_image(bbox, img, reshape_size = 512):\n",
    "    h, w, _ = img.shape\n",
    "    x1, y1, x2, y2 = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "\n",
    "    center_point = [int((x1 + x2) / 2), int((y1 + y2) / 2)] ## recalculate the center point\n",
    "    expand_size = int((y2 - y1)) # expand_size -- half of the total crop size\n",
    "    crop_size = expand_size * 2\n",
    "\n",
    "    new_x1 = center_point[0] - expand_size\n",
    "    new_x2 = center_point[0] + expand_size\n",
    "    new_y1 = center_point[1] - expand_size\n",
    "    new_y2 = center_point[1] + expand_size\n",
    "\n",
    "    (crop_left, origin_left) = (0, new_x1) if new_x1 >= 0 else (-new_x1, 0)\n",
    "    (crop_right, origin_right) = (crop_size, new_x2) if new_x2 <= w else (w-new_x1, w)\n",
    "    (crop_top, origin_top) = (0, new_y1) if new_y1 >= 0 else (-new_y1, 0)\n",
    "    (crop_bottom, origin_bottom) = (crop_size, new_y2) if new_y2 <= h else (h-new_y1, h)\n",
    "\n",
    "    aligned_img = np.zeros((crop_size, crop_size, 3), dtype=np.uint8)\n",
    "    aligned_img[crop_top:crop_bottom, crop_left:crop_right] = img[origin_top:origin_bottom, origin_left:origin_right]\n",
    "    aligned_img = Image.fromarray(aligned_img)\n",
    "    aligned_img = aligned_img.resize((reshape_size, reshape_size))\n",
    "    aligned_img = np.asarray(aligned_img)\n",
    "    return aligned_img\n",
    "\n",
    "def save_croped_images(frame_list, bboxlist, save_path):\n",
    "    os.makedirs(save_path, exist_ok= True)\n",
    "    index = 0\n",
    "\n",
    "    for i in range(len(frame_list)):\n",
    "        if i >= len(bboxlist):\n",
    "            break\n",
    "        bbox = bboxlist[i]\n",
    "        if bbox is None or len(bbox) == 0:\n",
    "            continue\n",
    "\n",
    "        frame = crop_image(bbox, frame_list[i])\n",
    "        # 设置保存文件名\n",
    "        image_save_path = \"{}/{}.png\".format(save_path, str(index).zfill(8))\n",
    "        # 保存图片\n",
    "        cv2.imwrite(image_save_path, frame)\n",
    "        index += 1  # 保存图片数＋1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = extract_frames(video_path)\n",
    "\n",
    "imgs_numpy = np.asarray(frame_list)[..., ::-1].copy()\n",
    "imgs_numpy = imgs_numpy.transpose(0, 3, 1, 2) # (ALL, 3, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bbox\n",
    "imgs_tensor = torch.from_numpy(imgs_numpy).cuda()\n",
    "bboxlist = get_BBox(imgs_tensor, face_detector, batch_size=batch_size) # (ALL, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = video_path.split('/')[-1]\n",
    "save_name = save_name.split('.')[0]\n",
    "\n",
    "save_path = os.path.join(extract_root_path, save_name)\n",
    "\n",
    "save_croped_images(frame_list, bboxlist, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
